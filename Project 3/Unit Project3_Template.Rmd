---
title: '[Unit Project 3 Template/Name your project here]'
authors: '[Team Number and Names]'
date: 
output: html_document

---
## Delete lines 8 - 16 section before submitting the file
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook to use as a template for your Unit 2 Project. 

Add new chunks by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).  You may need to Knit to HTML, using the KNIT button on the toolbar. 

You will submit both the saved R Markdown file (.RMD) WITH A NEW NAME and the HTML file.
## Delete lines 8-16 before submitting the file.

**To:** [Add Name here and remove brackets]

**From:**[Add Team Members names here and remove brackets ]

**Subject:** [Add Subject here and remove brackets]


## Background
[Provide a brief (one to two paragraphs, please, that 1) recaps the key features of your dataset, 2) states your task as a follow-up of your previous data exploration.  You may use a table to summarize your dataset features, if you wish.]
```{r setup, include =FALSE}
#Loading Libraries
#install.packages('GGally')
#install.packages('psych')
library(tidyverse)
library(GGally)
library(psych)
library(car)
library(statsr)
library (pwr)

#Loading Dataset
vgs <- read.csv('replaced variables.csv')

#Transforming variables to appropriate data types
vgs$NA_Sales<-as.numeric(vgs$NA_Sales)
vgs$EU_Sales<-as.numeric(vgs$EU_Sales)
vgs$JP_Sales<-as.numeric(vgs$JP_Sales)
vgs$Other_Sales<-as.numeric(vgs$Other_Sales)
vgs$Platform <- as.factor(vgs$Platform)
vgs$Publisher <- as.factor(vgs$Genre)
vgs$Genre <- as.factor(vgs$Genre)
vgs$Developer <- as.factor(vgs$Developer)
vgs$Rating <- as.factor(vgs$Rating)
vgs$Year_of_Release <- as.factor(vgs$Year_of_Release)
vgs$User_Score <- as.numeric(vgs$User_Score)
vgs$Name <- as.character(vgs$Name)
vgs$User_Score <- vgs$User_Score * 10

#Replacing empty entries with NA
vgs$Rating[vgs$Rating %in% c("")]<- NA
vgs$Rating <-factor(vgs$Rating)
vgs$Developer[vgs$Developer %in% c("")]<- NA
vgs$Developer <-factor(vgs$Developer)
vgs$Genre[vgs$Genre %in% c("")]<- NA
vgs$Genre <-factor(vgs$Genre)
vgs <- filter(vgs, Name != "")
```

## Analyses

### Analysis 1: [Name/Description]
#### Analyst:[Name of Team Member]

In this analysis, I am testing to see whether there is an association between the age of the intended audience of a video game and the platform it is released on. I have simplified the originally reported ESRB ratings for the video games in the data set by fitting them into new categories labeled as "kids", "teens", and "adults" in order to make the results of the test more readable and practical. I've also removed all observations where the rating is listed as "RP", or Rating Pending. The most appropriate statistical test to measure the association between two categorical variables is a Chi-square test of independence.

In order to determine if the Chi-square test was a viable option to analyze this data, I first needed to make sure the data meets all of the conditions. The data meets the condition of independence as each observation is independent of all the others. Some data wrangling was required to make this true. I chose to completely remove all observations which had duplicate names. Some of these entries seemed to be completely erroneous, where there were two or more entires which were exact copies. It's also common for single games to be released on multiple platforms. I have eliminated all cases where this is true, opting instead to keep only those which were intended for only one platform. The data meet the sample size condition as each category has more than 5 cases. In this case, the condition is far exceeded, with the lowest number of cases being 54 (PC games made for an adult audience) and the highest being 2176 (handheld games made for kids). The degrees of freedom is determined by the number of rows and columns in our data set, with the formula (R-1)x(C-1). The data frame consists of 3 rows and 3 columns, therefore the degrees of freedom for this test is 4. This number is corroborated by the results of our chi-squared test in R.

The null hypothesis states that the rating and platform are independent - the rating does not vary by platform, and our alternative hypothesis is that rating and platform are dependent - the rating does vary by platform. After running the Chi-squared test on our contingency table, I got a p-value of p < 2.2e-16, which is very large, and therefore we will not reject the null hypothesis. Based on our test, there is no evidence that the rating of a video game has any effect on the platform that it gets released on.

```{r}
# copy to a new working dataset
vgs_chi <- vgs

# drop observations from the new dataset that have a duplicate name
vgs_chi <- vgs_chi[!(duplicated(vgs_chi$Name) | duplicated(vgs_chi$Name, fromLast = TRUE)), ]

# filter out all obvservations which show a rating on RP, and drop that level entirely
vgs_chi <- filter(vgs_chi, Rating != "RP") %>% droplevels()

# select only rating and platform from the dataset
vgs_chi <- select(vgs_chi, Rating, Platform)

vgs_chi <- na.omit(vgs_chi)

# combine all platforms relating console products 
levels(vgs_chi$Platform)[levels(vgs_chi$Platform)%in%c("Wii", "NES", "X360", "PS3", "PS2", "SNES", "PS4", "N64", "PS", "XB", "2600", "XOne", "WiiU", "GC", "GEN", "DC", "SAT", "SCD", "NG", "TG16", "3DO", "PCFX")] <- "console"

# combine all platforms relating handheld products
levels(vgs_chi$Platform)[levels(vgs_chi$Platform)%in%c("GB", "DS", "GBA", "3DS", "PSP", "PSV", "WS", "GG")] <- "handheld"

# combine all ratings intended for ages under 18
levels(vgs_chi$Rating)[levels(vgs_chi$Rating)%in%c("E", "E10+", "K-A", "EC")] <- "kids"

# combine all ratings intended for teens
levels(vgs_chi$Rating)[levels(vgs_chi$Rating)%in%c("T")] <- "teens"

# combine all ratings intended for ages over 18
levels(vgs_chi$Rating)[levels(vgs_chi$Rating)%in%c("M", "AO")] <- "adults"

# view / inspect dataframe
view(vgs_chi)
unique(vgs_chi)
summary(vgs_chi)

# contingency table with new variables
chi_t <- table(vgs_chi$Rating, vgs_chi$Platform)

# check contingency table
chi_t

# create mosaic plot using the data in the contingency table
mosaicplot(chi_t, main = "Intended Audience Accross Platforms",ylab = "Platform", xlab = "Age Groups")

# perform chi-squared test
chisq.test(chi_t)

```



### Analysis 2: Name/description]
#### Analyst:[Name of Team Member]

[Put text of analysis here and add as many code chunks and text sections as you need.]


```{r}
#copying the table for my variables of choice
vgs_copy <- select(vgs, Rating, Global_Sales)

#removing NA values
vgs_annova <- na.omit(vgs_copy)

#post transformation
table(vgs_annova$Rating)

vgs_annova <- mutate(vgs_annova, Rating = ifelse(Rating == "E" | Rating == "E10+" | Rating == "EC" | Rating == "K-A", "E",
                                                 ifelse(Rating == "AO" | Rating == "M", "M", 
                                                        ifelse(Rating == "RP", "RP",
                                                               ifelse(Rating == "T", "T",
                                                                      Rating)))))

#check
table(vgs_annova$Rating)

#checking conditions
leveneTest(vgs_annova$Global_Sales ~ vgs_annova$Rating)

tapply(vgs_annova$Global_Sales, vgs_annova$Rating, qqnorm)

aov_test <- aov(data = vgs_annova, vgs_annova$Global_Sales ~ vgs_annova$Rating)
summary(aov_test)

TukeyHSD(aov_test)

ef <- effectsize::eta_squared(aov_test)
ef$Eta2

pwr.anova.test(k = 4, sig.level = 0.05, f = 0.007859374, n = c(5422, 1564, 3, 2961), power = NULL)

```




### Analysis 3: Simple Linear Regression - EU_Sales and JP_Sales
#### Analyst: Joey diFrancesco

For this analysis, I am testing to see if Japan sales have any affect or impact on European sales. I chose EU_Sales to be my quantitative response variable and JP_Sales to be my quantitative explanatory variable. To do this analysis, Simple Linear Regression using two quantitative variables is what I found to be best fit. 

To proceed with linear regression, all conditions must be identified and met. The first condition is for the Y values or "errors" to be independent. To see if this is met, we must look at the Residual plot. The red line is fairly straight with no pattern and abnormalities, therefore the condition is met. The next condition is for the relationship between the explanatory and response variables must be linear. In our scatter plot, the data can be shown using a straight line, therefore the relationship is linear and the condition is met. For our last condition, the data must be normally distributed. We must look at our Normal Q-Q plot and see that the line associated with the y values are on a slight diagonal and straight. This shows that what we expect the residual errors should be are normally distributed, therefore the condition is met. 

The null hypothesis for this analysis would be that the response variable is not independent and is affected by the explanatory variable, or EU_Sales is affected by JP_Sales. The alternative hypothesis would be that the response variable is independent of the explanatory variable, or EU_Sales is not affected by JP_Sales. My test statistic is t = 27.691, and p-value < 2.2e-16. Considering the p-value is extremely small and less than 0.05, we reject the null hypothesis. The R^2 value I got is 0.232 or 23.2%. This value is on the lower side, and can mean not many data points fall within the results of the line formed by the regression equation. In our case, it is more difficult to predict human behavior (buying video games) so therefore the R^2 value will be low. 

In conclusion, my analysis shows that Japan sales have little to no affect on European sales considering the null hypothesis was rejected.

```{r}
#Retrieving summary stats of both variables
describe(vgs$EU_Sales)
describe(vgs$JP_Sales)

#Scatterplot of both variables and adding a regression line to the plot
ggplot(vgs, aes(x = JP_Sales, y = EU_Sales )) + xlim(0, 12) + ylim(0,15) +
    geom_point() + geom_smooth(method=lm, se=FALSE)

#Finding the correlation of the two variables with a 95% confidence level
cor.test(vgs$JP_Sales, vgs$EU_Sales, method = "pearson", conf.level = 0.95)

#Running the regression and calling the linear model mod
mod <- lm(vgs$EU_Sales ~ vgs$JP_Sales)
summary(mod)

#Determining with plots whether the data meets the conditions for a linear model
plot(mod)
```




### Analysis 4:[Name/description]
#### Analyst:[Christopher Aguila]

[Put text of analysis here and add as many code chunks and text sections as you need.]

# Clearly identify explanatory and response variables

# State the conditions and tell how each condition is met. Refer to any calculations, visualizations, or diagnostics that you use to justify this.

# State the null and alternative hypothesis of this analysis in words in the context of your data.

# Write the regression model. Interpret each estimated coefficient, if appropriate.

#In your written analysis, properly identify the test statistis and p-value for each coefficient, and state whether or not you reject the null hypothesis.

# State and interpret the adjusted R^2, then give a summary conclusion in the context of your data.

#Discuss any limitations to your analysis due to conditions not met, sampling bias, outliers in the data, or other issues that you notice. Reference your output from the R analysis as needed.

```{r}
#Viewing the main features of the dataset
dim (vgs)
names (vgs)
str (vgs)
head (vgs)
tail (vgs)

#Summary stats using Psych
describe(vgs$EU_Sales)

# Select and identify quantitative response variable and at least two explanatory quantitative variables: The response variable will be EU sales while the explanatory variables will be NA sales and JP sales.

# Boxplot and histogram of EU Sales
ggplot(data=vgs) +
  geom_boxplot(mapping=aes(x=EU_Sales))
ggplot(data = vgs) +
  geom_histogram(mapping = aes(x = EU_Sales), binwidth = 0.5)

# Show any transformations done to your variables.
vgs_comp <- vgs[complete.cases(vgs), ]

#Create table of correlation and covariance for your variables.
res <- vgs_comp %>%
  select_if(is.numeric)%>%
  cor()

# Determine whether your data meets the conditions for a linear model. State the conditions for a linear model. Perform all appropriate diagnostics. Show any calculations or visualizations that you use to justify this.

#Run The regression.
model <- lm(EU_Sales ~ NA_Sales + JP_Sales, data = vgs_comp)
summary(model)
```




### Analysis 5:[Name/description]
#### Analyst: Samson Joseph

[Put text of analysis here and add as many code chunks and text sections as you need.]

```{r}
describe(vgs$EU_Sales)
NA_sales_A5 <- data.frame(NA_Sales=vgs$NA_Sales[!is.na(vgs$NA_Sales)])
EU_Sales_A5 <- data.frame(EU_Sales=vgs$EU_Sales[!is.na(vgs$EU_Sales)])

ggplot(EU_Sales_A5,aes(x='',EU_Sales)) + geom_boxplot() + ylim(0,.42) +ylab('EU Sales')

ggplot(EU_Sales_A5, aes(x=EU_Sales)) + geom_histogram(binwidth = .01) + xlim(.01,1)


# vgs_comp <- na.omit(vgs)
# res <- data.frame( vgs_comp %>%
#   select_if(is.numeric) %>%
#   cor())
# res
# 
# model <- lm(EU_Sales ~ NA_Sales, data = vgs_comp)
# summary(model)

qqnorm(model$residuals)
qqline(model$residuals)

A5 <- vgs %>%
  select(EU_Sales, NA_Sales, Platform) %>%
  filter(Platform == "PS4" | Platform == "XOne")
A5<-na.omit(A5)


corT <- data.frame(A5 %>%
  select_if(is.numeric) %>%
  cor())
corT
A5 %>%
  select_if(is.numeric) %>%
  ggpairs()

Mlm <- model <- lm(EU_Sales ~ NA_Sales + Platform, data = A5)
summary(Mlm)

plot(Mlm$residuals ~ A5$EU_Sales,xlim=c(0,.5))
abline(h = 0, lty = 3)
leveragePlots(Mlm, xlim=c(-.5,.5))

sigma(Mlm)/mean(A5$EU_Sales)

anova(Mlm)
```





## Recommendations

[Add text section with your recommendations here. In this section, you will briefly  summarize the conclusions of your estimates and tests. What statistically significant findings did you have?  What limitations are there in your findings?  Discuss if/how this is relevant in the context of your data â€“ does it give us new insights ? Help us to better understand some phenomenon?  Or not?]

## Reflections
[Add text section on your reflections about unit projects. Be sure to address each of the prompts on the instruction sheet.]