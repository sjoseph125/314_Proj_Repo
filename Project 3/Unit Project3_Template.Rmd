---
title: 'Unit Project 3: Analysis Using simple and multiple linear regression '
authors: 'Samson Joseph, Sean Simmons, Daniel Gurwah, Joseph Difrancesco'
date: "5/10/2021"
output:
  html_document:
    df_print: paged
---
## Delete lines 8 - 16 section before submitting the file
This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook to use as a template for your Unit 2 Project. 

Add new chunks by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).  You may need to Knit to HTML, using the KNIT button on the toolbar. 

You will submit both the saved R Markdown file (.RMD) WITH A NEW NAME and the HTML file.
## Delete lines 8-16 before submitting the file.

**To:** DR. Random<br>

**From:** Samson Joseph, Sean Simmons, Daniel Gurwah, Christopher Aguila, Joseph Difrancesco<br>

**Subject:**Analysis of Video Games Dataset Using Linear Regression 


## Background
[Provide a brief (one to two paragraphs, please, that 1) recaps the key features of your dataset, 2) states your task as a follow-up of your previous data exploration.  You may use a table to summarize your dataset features, if you wish.]
```{r setup, include =FALSE}
#Loading Libraries
#install.packages('GGally')
#install.packages('psych')
library(tidyverse)
library(GGally)
library(psych)
library(car)
library(statsr)
library (pwr)

#Loading Dataset
vgs <- read.csv('replaced variables.csv')

#Transforming variables to appropriate data types
vgs$NA_Sales<-as.numeric(vgs$NA_Sales)
vgs$EU_Sales<-as.numeric(vgs$EU_Sales)
vgs$JP_Sales<-as.numeric(vgs$JP_Sales)
vgs$Other_Sales<-as.numeric(vgs$Other_Sales)
vgs$Platform <- as.factor(vgs$Platform)
vgs$Publisher <- as.factor(vgs$Genre)
vgs$Genre <- as.factor(vgs$Genre)
vgs$Developer <- as.factor(vgs$Developer)
vgs$Rating <- as.factor(vgs$Rating)
vgs$Year_of_Release <- as.factor(vgs$Year_of_Release)
vgs$User_Score <- as.numeric(vgs$User_Score)
vgs$Name <- as.character(vgs$Name)
vgs$User_Score <- vgs$User_Score * 10

#Replacing empty entries with NA
vgs$Rating[vgs$Rating %in% c("")]<- NA
vgs$Rating <-factor(vgs$Rating)
vgs$Developer[vgs$Developer %in% c("")]<- NA
vgs$Developer <-factor(vgs$Developer)
vgs$Genre[vgs$Genre %in% c("")]<- NA
vgs$Genre <-factor(vgs$Genre)
vgs <- filter(vgs, Name != "")
```

## Analyses

### Analysis 1: [Name/Description]
#### Analyst:[Name of Team Member]

In this analysis, I am testing to see whether there is an association between the age of the intended audience of a video game and the platform it is released on. I have simplified the originally reported ESRB ratings for the video games in the data set by fitting them into new categories labeled as "kids", "teens", and "adults" in order to make the results of the test more readable and practical. I've also removed all observations where the rating is listed as "RP", or Rating Pending. The most appropriate statistical test to measure the association between two categorical variables is a Chi-square test of independence.

In order to determine if the Chi-square test was a viable option to analyze this data, I first needed to make sure the data meets all of the conditions. The data meets the condition of independence as each observation is independent of all the others. Some data wrangling was required to make this true. I chose to completely remove all observations which had duplicate names. Some of these entries seemed to be completely erroneous, where there were two or more entires which were exact copies. It's also common for single games to be released on multiple platforms. I have eliminated all cases where this is true, opting instead to keep only those which were intended for only one platform. The data meet the sample size condition as each category has more than 5 cases. In this case, the condition is far exceeded, with the lowest number of cases being 54 (PC games made for an adult audience) and the highest being 2176 (handheld games made for kids). The degrees of freedom is determined by the number of rows and columns in our data set, with the formula (R-1)x(C-1). The data frame consists of 3 rows and 3 columns, therefore the degrees of freedom for this test is 4. This number is corroborated by the results of our chi-squared test in R.

The null hypothesis states that the rating and platform are independent - the rating does not vary by platform, and our alternative hypothesis is that rating and platform are dependent - the rating does vary by platform. After running the Chi-squared test on our contingency table, I got a p-value of p < 2.2e-16, which is very large, and therefore we will not reject the null hypothesis. Based on our test, there is no evidence that the rating of a video game has any effect on the platform that it gets released on.

```{r}
# copy to a new working dataset
vgs_chi <- vgs

# drop observations from the new dataset that have a duplicate name
vgs_chi <- vgs_chi[!(duplicated(vgs_chi$Name) | duplicated(vgs_chi$Name, fromLast = TRUE)), ]

# filter out all obvservations which show a rating on RP, and drop that level entirely
vgs_chi <- filter(vgs_chi, Rating != "RP") %>% droplevels()

# select only rating and platform from the dataset
vgs_chi <- select(vgs_chi, Rating, Platform)

vgs_chi <- na.omit(vgs_chi)

# combine all platforms relating console products 
levels(vgs_chi$Platform)[levels(vgs_chi$Platform)%in%c("Wii", "NES", "X360", "PS3", "PS2", "SNES", "PS4", "N64", "PS", "XB", "2600", "XOne", "WiiU", "GC", "GEN", "DC", "SAT", "SCD", "NG", "TG16", "3DO", "PCFX")] <- "console"

# combine all platforms relating handheld products
levels(vgs_chi$Platform)[levels(vgs_chi$Platform)%in%c("GB", "DS", "GBA", "3DS", "PSP", "PSV", "WS", "GG")] <- "handheld"

# combine all ratings intended for ages under 18
levels(vgs_chi$Rating)[levels(vgs_chi$Rating)%in%c("E", "E10+", "K-A", "EC")] <- "kids"

# combine all ratings intended for teens
levels(vgs_chi$Rating)[levels(vgs_chi$Rating)%in%c("T")] <- "teens"

# combine all ratings intended for ages over 18
levels(vgs_chi$Rating)[levels(vgs_chi$Rating)%in%c("M", "AO")] <- "adults"

# view / inspect dataframe
view(vgs_chi)
unique(vgs_chi)
summary(vgs_chi)

# contingency table with new variables
chi_t <- table(vgs_chi$Rating, vgs_chi$Platform)

# check contingency table
chi_t

# create mosaic plot using the data in the contingency table
mosaicplot(chi_t, main = "Intended Audience Accross Platforms",ylab = "Platform", xlab = "Age Groups")

# perform chi-squared test
chisq.test(chi_t)

```



### Analysis 2: Analysis of Variance Test
#### Analyst:Daniel Gurwah

In this analysis I will be performing an Analysis of Variance (ANNOVA) test to find if there is a difference in the means across the groups in the ratings category. I will be using the global sales variable as the quantitative or the response variable and the ratings will be used as the categorical or explanatory variable. To use the ratings I combined some of the categories in order to have less overlap of similar factors. I combined all of the everyone categories together, all of the adult categories together, and left everything else how they were. 

To perform an ANNOVA test, first a Levene test is ran to check the homogeniety of the variance between treatment groups and a QQNorm graph is ran to check the normality of each treatment group. For a Levene test the null hypothesis is there is no difference between treatment groups. The p-value of 9.527e-15 is very small and therefore we reject the null hypothesis. This means that there are differences between the treatment groups. After running the qqnorm graphs, it can be seen that in all of the groups besides one they are reflective of an exponential type of curve. This means that there is most likely not normality in the groups. 

**Null Hypothesis:** The mean between all treatment groups are the same. 

**Alternative Hypothesis:** The mean is different for at least one of the treatment groups.

After running the ANNOVA test the p-value is 2.53e-16 and the f-statistic is 0.007859374. Since the p-value is very small we will reject the null hypothesis. This means that there is strongly significant evidence of a difference between the different ratings and global sales.When running the power for each of these groups, they are all extremely low. For the everyone, mature, RP, and teen groups they have powers of: 0.14069527, 0.07371485, 0.05002809, 0.09672216. In order to obtain a power of at least 0.8 and avoid a type II error the groups should be 44126.79 total sales. The powers of these categories are so low due to the f-statistic being so low. In this case running a parametric test will be better since these variables did not meet the criteria for an ANNOVA test. 


```{r}
#copying the table for my variables of choice
vgs_copy <- select(vgs, Rating, Global_Sales)

#removing NA values
vgs_annova <- na.omit(vgs_copy)

#post transformation
table(vgs_annova$Rating)

vgs_annova <- mutate(vgs_annova, Rating = ifelse(Rating == "E" | Rating == "E10+" | Rating == "EC" | Rating == "K-A", "E",
                                                 ifelse(Rating == "AO" | Rating == "M", "M", 
                                                        ifelse(Rating == "RP", "RP",
                                                               ifelse(Rating == "T", "T",
                                                                      Rating)))))

#check
table(vgs_annova$Rating)

#checking conditions
leveneTest(vgs_annova$Global_Sales ~ vgs_annova$Rating)

tapply(vgs_annova$Global_Sales, vgs_annova$Rating, qqnorm)

aov_test <- aov(data = vgs_annova, vgs_annova$Global_Sales ~ vgs_annova$Rating)
summary(aov_test)

TukeyHSD(aov_test)

ef <- effectsize::eta_squared(aov_test)
ef$Eta2

pwr.anova.test(k = 4, sig.level = 0.05, f = 0.007859374, n = c(5422, 1564, 3, 2961), power = NULL)

pwr.anova.test(k = 4, sig.level = 0.05, f = 0.007859374, n = NULL, power = .8)

```




### Analysis 3: Simple Linear Regression - EU_Sales and JP_Sales
#### Analyst: Joey diFrancesco

[Put text of analysis here and add as many code chunks and text sections as you need.]

```{r}
#Retrieving summary stats of both variables
describe(vgs$EU_Sales)
describe(vgs$JP_Sales)

#Scatterplot of both variables and adding a regression line to the plot
ggplot(vgs, aes(x = JP_Sales, y = EU_Sales )) + xlim(0, 12) + ylim(0,15) +
    geom_point() + geom_smooth(method=lm, se=FALSE)

#Finding the correlation of the two variables with a 95% confidence level
cor.test(vgs$JP_Sales, vgs$EU_Sales, method = "pearson", conf.level = 0.95)

#Running the regression and calling the linear model mod
mod <- lm(vgs$EU_Sales ~ vgs$JP_Sales)
summary(mod)

#Determining with plots whether the data meets the conditions for a linear model
par(mfrow=c(2,2))
plot(mod)
```




### Analysis 4:[Name/description]
#### Analyst:[Christopher Aguila]

[Put text of analysis here and add as many code chunks and text sections as you need.]

# Clearly identify explanatory and response variables

# State the conditions and tell how each condition is met. Refer to any calculations, visualizations, or diagnostics that you use to justify this.

# State the null and alternative hypothesis of this analysis in words in the context of your data.

# Write the regression model. Interpret each estimated coefficient, if appropriate.

#In your written analysis, properly identify the test statistis and p-value for each coefficient, and state whether or not you reject the null hypothesis.

# State and interpret the adjusted R^2, then give a summary conclusion in the context of your data.

#Discuss any limitations to your analysis due to conditions not met, sampling bias, outliers in the data, or other issues that you notice. Reference your output from the R analysis as needed.

```{r}
#Viewing the main features of the dataset
dim (vgs)
names (vgs)
str (vgs)
head (vgs)
tail (vgs)

#Summary stats using Psych
describe(vgs$EU_Sales)

# Select and identify quantitative response variable and at least two explanatory quantitative variables: The response variable will be EU sales while the explanatory variables will be NA sales and JP sales.

# Boxplot and histogram of EU Sales
ggplot(data=vgs) +
  geom_boxplot(mapping=aes(x=EU_Sales))
ggplot(data = vgs) +
  geom_histogram(mapping = aes(x = EU_Sales), binwidth = 0.5)

# Show any transformations done to your variables.
vgs_comp <- vgs[complete.cases(vgs), ]

#Create table of correlation and covariance for your variables.
res <- vgs_comp %>%
  select_if(is.numeric)%>%
  cor()

# Determine whether your data meets the conditions for a linear model. State the conditions for a linear model. Perform all appropriate diagnostics. Show any calculations or visualizations that you use to justify this.

#Run The regression.
model <- lm(EU_Sales ~ NA_Sales + JP_Sales, data = vgs_comp)
summary(model)
```




### Analysis 5: Multiple Regression with EU_Sales, NA_Sales and Platform
#### Analyst: Samson Joseph

The response variable used in this analysis is EU_Sales. And the explanatory variables are NA_Sales, the quantitative variable, and Platform, the categorical variable. The Platform variable has been simplified to only include the PS4 and XOne values. The conditions for conducting the regression model are discussed below, close to the necessary graphs to visualize the information. The null hypothesis would be getting correlation coefficients that are equal to 0. The alternative hypothesis would be getting correlation coefficients that are not equal to 0. After running the model, we get an estimated coefficient of 0.79071 for NA_Sales and -0.33644 for Platform. Both coefficients are meaningfully different from 0. And their respective p-values are considerably less than any significance level. Additionally, with an F statistic of 236.1 and a p-value which is considerably less than .05, we can confidently reject the null hypothesis. The resulting adjusted R^2 value is only .516 which is not very high. This tells us that only 51.6% of the variation in the EU_Sales data can be explained by the regression model. The other 48.4% of the variation is a result of variables not considered for the regression or is a result of pure randomness. The linear equation EU_Sales = 0.22654 + 0.79071 * NA_Sales -.33644 * (1 for XOne and 0 for PS4) can be explained as such. This model can predict that for every x amount of sales in North America, sales in the EU will be .79071 of the x plus .22654. Additionally if the game is for XOne, the sales will be .3364 less and if the game is for PS4 then the sales will be .3364 more. With an R^2 of .516, this method can only explain 51.6% of the variation, so other variables must be considered for a better linear model.

In conclusion, the conditions for linear modeling is mostly met, and the resulting p-values for the estimated coefficients and F statistic are all well below that of any significance level. Therefore, the null hypothesis of zero correlation between the variables EU_Sales, NA_Sales, and Platform is rejected.



```{r warning=FALSE}

NA_sales_A5 <- data.frame(NA_Sales=vgs$NA_Sales[!is.na(vgs$NA_Sales)])
EU_Sales_A5 <- data.frame(EU_Sales=vgs$EU_Sales[!is.na(vgs$EU_Sales)])

#Showing the distribution of EU_Sales
#A limit of .27 was applied to the y axis of the boxplot and the x axis of the histogram to the data without the outliers. 0.27 was calculated by multiplying the IQR of EU_Sales, which is .18 by 1.5.

ggplot(EU_Sales_A5,aes(x='',EU_Sales)) + geom_boxplot() + ylim(0,.27) +ylab('EU Sales')

ggplot(EU_Sales_A5, aes(x=EU_Sales)) + geom_histogram(binwidth = .01) + xlim(.01,.27)

describe(vgs$EU_Sales)
```


The graph and table below help visualize the linearity of the variables, EU_Sales and NA_Sales. With a correlation of .68, they do have a linear relationship.

```{r warning=FALSE}
#Created a new DataFrame that includes EU_Sales, the response variable, and NA_Sales and Platform, the explanatory variables.
A5 <- vgs %>%
  select(EU_Sales, NA_Sales, Platform) %>%
  filter(Platform == "PS4" | Platform == "XOne")
A5<-na.omit(A5)

#Making a scatter plot to compare EU_Sales with NA_Sales in order to visualize any trends.
plot(A5$EU_Sales~A5$NA_Sales, xlim=c(0,.47))
plot(A5$EU_Sales~A5$NA_Sales, xlim=c(0,.47), ylim=c(0,.27)) #.27

#Creating a DataFrame to analyze the correlation of EU_Sales and NA_Sales
corT <- data.frame(A5 %>%
  select_if(is.numeric) %>%
  cor())
corT

```
The first and second graph in below section give visualizations on the residuals of the model. The first plot shows a good scatter among the residuals. Although not the ideal spread, it is enough to satisfy the condition of the residual independence. In order to check the normality of the residuals we will use a histogram and a qqnorm graph. The histogram shows a bimodal distribution and the qqnorm is relatively satisfactory, with some quirkiness at the ends. The bimodal distribution is not too severe, but is mostly satisfactory. But homoscedasticity of the residuals is a bit more questionable as there is a meaningful amount below the 0 line than above.

```{r warning=FALSE}

#Creating a multi-linear regression model
Mlm <- model <- lm(EU_Sales ~ NA_Sales + Platform, data = A5)
summary(Mlm)

#Plotting the residuals to visualize their variability
plot(Mlm$residuals ~ A5$EU_Sales,xlim=c(0,.5), ylim=c(-1,.5))
abline(h = 0, lty = 3)
hist(Mlm$residuals, breaks = 50)

qqnorm(Mlm$residuals)
qqline(Mlm$residuals)

leveragePlots(Mlm, xlim=c(-.5,.5))

sigma(Mlm)/mean(A5$EU_Sales)

anova(Mlm)

```





## Recommendations

[Add text section with your recommendations here. In this section, you will briefly  summarize the conclusions of your estimates and tests. What statistically significant findings did you have?  What limitations are there in your findings?  Discuss if/how this is relevant in the context of your data â€“ does it give us new insights ? Help us to better understand some phenomenon?  Or not?]

## Reflections
[Add text section on your reflections about unit projects. Be sure to address each of the prompts on the instruction sheet.]